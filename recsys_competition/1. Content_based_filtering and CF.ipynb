{"cells":[{"cell_type":"markdown","metadata":{"id":"EFcNIZX_dNEL"},"source":["## [0] 실습 소개\n","\n","이번 실습에서 해볼 내용\n","- Jaccard similarity 를 이용한 Content-based filtering\n","- TF-IDF 를 이용한 텍스트 데이터 vectorizing\n","- 다양한 유사도 계산을 활용한 Content-based filtering\n","- User-based CF\n","- Item-based CF\n","- K-Means Clustering과 Item-based CF\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"dCKt0c3mhoeI"},"source":["### 데이터 불러오기\n","\n","RecSys 기초 대회 강의에서는Book Crossing 데이터를 사용하여, 모든 실습 및 미션, 대회를 진행합니다. [Kaggle Book-Crossing](https://www.kaggle.com/datasets/ruchi798/bookcrossing-dataset) 을 출처로 하며, 데이터는 재구성되어 제공되었습니다. 해당 데이터는 CC0: Public Domain 라이센스임을 밝힙니다.\n","\n","- 데이터 특징\n","    - 책에 대한 제목, 장르, 출판년도, 작가 등의 데이터가 있음.\n","    - 유저에 대한 연령, 거주 지역 등의 데이터가 있음.\n","    - Explicit Feedback: 유저가 책에 대한 선호도를 1 ~ 10 사이의 점수로 표현함.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"AVV4NPjiH853"},"source":["실습할 데이터를 불러와서merge 합니다.\n","\n","이번 시간에 실습하는 2강_실습_dataset_ratings.csv 파일은 원본 파일에서 평가 횟수가 적은 사용자를 일부 삭제한 파일입니다."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8520,"status":"ok","timestamp":1677656529135,"user":{"displayName":"강진영","userId":"15199531416785753238"},"user_tz":-540},"id":"HL5kiI8tH8nO","outputId":"d265e8c3-69b9-43a3-d206-eb13fe1d9239"},"outputs":[],"source":["!wget --load-cookies ~/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies ~/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1-49AjeQvRML0_UzzCeQ9t6LJ1b_X_2GZ' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1-49AjeQvRML0_UzzCeQ9t6LJ1b_X_2GZ\" -O books.csv && rm -rf ~/cookies.txt\n","!wget --load-cookies ~/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies ~/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1gJK_FU4gaSf5rocXBWp8nt1eNyRr-NrR' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1gJK_FU4gaSf5rocXBWp8nt1eNyRr-NrR\" -O ratings.csv && rm -rf ~/cookies.txt\n","!wget --load-cookies ~/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies ~/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1-5loL2Z1D9t-yddAf5N4vciT_1fd-cm7' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1-5loL2Z1D9t-yddAf5N4vciT_1fd-cm7\" -O users.csv && rm -rf ~/cookies.txt"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"wWIU7bkXCXOu"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from typing import List, Set,Optional\n","path=''"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1029,"status":"ok","timestamp":1677656547381,"user":{"displayName":"강진영","userId":"15199531416785753238"},"user_tz":-540},"id":"Cw5yvmd4sChO","outputId":"547dd0fb-82f4-4305-a9a1-fe4e3cc50ad0"},"outputs":[{"name":"stdout","output_type":"stream","text":["books shape:  (232348, 6)\n","users shape:  (79516, 3)\n","ratings shape:  (56290, 3)\n"]}],"source":["books = pd.read_csv(path+'books.csv')\n","users = pd.read_csv(path+'users.csv')\n","ratings = pd.read_csv(path+'ratings.csv')\n","\n","print('books shape: ', books.shape)\n","print('users shape: ', users.shape)\n","print('ratings shape: ', ratings.shape)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1677656547382,"user":{"displayName":"강진영","userId":"15199531416785753238"},"user_tz":-540},"id":"3yrA0ckIAgWU","outputId":"5113cffa-7a54-4c51-a416-41a25a8a0fd7"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>isbn</th>\n","      <th>book_title</th>\n","      <th>book_author</th>\n","      <th>publisher</th>\n","      <th>language</th>\n","      <th>category</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0002005018</td>\n","      <td>Clara Callan</td>\n","      <td>Richard Bruce Wright</td>\n","      <td>HarperFlamingo Canada</td>\n","      <td>en</td>\n","      <td>['Actresses']</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0060973129</td>\n","      <td>Decision in Normandy</td>\n","      <td>Carlo D'Este</td>\n","      <td>HarperPerennial</td>\n","      <td>en</td>\n","      <td>['1940-1949']</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0374157065</td>\n","      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n","      <td>Gina Bari Kolata</td>\n","      <td>Farrar Straus Giroux</td>\n","      <td>en</td>\n","      <td>['Medical']</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0393045218</td>\n","      <td>The Mummies of Urumchi</td>\n","      <td>E. J. W. Barber</td>\n","      <td>W. W. Norton &amp; Company</td>\n","      <td>en</td>\n","      <td>['Design']</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0399135782</td>\n","      <td>The Kitchen God's Wife</td>\n","      <td>Amy Tan</td>\n","      <td>Putnam Pub Group</td>\n","      <td>en</td>\n","      <td>['Fiction']</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         isbn                                         book_title  \\\n","0  0002005018                                       Clara Callan   \n","1  0060973129                               Decision in Normandy   \n","2  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n","3  0393045218                             The Mummies of Urumchi   \n","4  0399135782                             The Kitchen God's Wife   \n","\n","            book_author               publisher language       category  \n","0  Richard Bruce Wright   HarperFlamingo Canada       en  ['Actresses']  \n","1          Carlo D'Este         HarperPerennial       en  ['1940-1949']  \n","2      Gina Bari Kolata    Farrar Straus Giroux       en    ['Medical']  \n","3       E. J. W. Barber  W. W. Norton & Company       en     ['Design']  \n","4               Amy Tan        Putnam Pub Group       en    ['Fiction']  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["books.head()"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1677656548870,"user":{"displayName":"강진영","userId":"15199531416785753238"},"user_tz":-540},"id":"2k_0widDAgvs","outputId":"ecaa6e3a-44a2-4b7d-f116-2b79afdeda44"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>location</th>\n","      <th>age</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>8</td>\n","      <td>timmins, ontario, canada</td>\n","      <td>34</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>11400</td>\n","      <td>ottawa, ontario, canada</td>\n","      <td>49</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>11676</td>\n","      <td>n/a, n/a, n/a</td>\n","      <td>34</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>41385</td>\n","      <td>sudbury, ontario, canada</td>\n","      <td>34</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>67544</td>\n","      <td>toronto, ontario, canada</td>\n","      <td>30</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   user_id                  location  age\n","0        8  timmins, ontario, canada   34\n","1    11400   ottawa, ontario, canada   49\n","2    11676             n/a, n/a, n/a   34\n","3    41385  sudbury, ontario, canada   34\n","4    67544  toronto, ontario, canada   30"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["users.head()"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1677656549533,"user":{"displayName":"강진영","userId":"15199531416785753238"},"user_tz":-540},"id":"zh_Yzn-MBZce","outputId":"3730904b-aa0b-4f68-e2d5-a63bcb5bcb92"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>isbn</th>\n","      <th>rating</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>243</td>\n","      <td>0446606383</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>243</td>\n","      <td>0446605484</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>243</td>\n","      <td>0446600474</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>243</td>\n","      <td>0446364800</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>243</td>\n","      <td>0446360856</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   user_id        isbn  rating\n","0      243  0446606383       6\n","1      243  0446605484       1\n","2      243  0446600474       1\n","3      243  0446364800       9\n","4      243  0446360856       1"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["ratings.head()"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"jw6njw_R27-J"},"outputs":[],"source":["df = ratings.merge(books, on='isbn')\n","df = df.merge(users, on='user_id', how='inner')"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1677656551522,"user":{"displayName":"강진영","userId":"15199531416785753238"},"user_tz":-540},"id":"08Ql_hGH06IX","outputId":"aadc30c6-9aa0-4f11-a528-4a44dfec6ffb"},"outputs":[{"data":{"text/plain":["(56290, 10)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["df.shape"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1677656553243,"user":{"displayName":"강진영","userId":"15199531416785753238"},"user_tz":-540},"id":"HzvLXhQYxS7E","outputId":"f09b9b70-1ec8-48db-f0b2-c3e2137d2e7e"},"outputs":[{"data":{"text/plain":["916"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# Return number of unique elements in the object. Excludes NA values by default.\n","df['book_title'].nunique() # 총 몇개의 책이 있는지 살펴봅니다."]},{"cell_type":"code","execution_count":9,"metadata":{"id":"kl36P5QSnh2x"},"outputs":[{"data":{"text/plain":["array(['The Midnight Club', 'Roses Are Red (Alex Cross Novels)',\n","       'Season of the Machete', \"The General's Daughter\",\n","       'The Gold Coast'], dtype=object)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# 뽑힌 책을 list로 만들고 활용하겠습니다.\n","book_title_list = df['book_title'].unique()\n","book_title_list[:5]"]},{"cell_type":"markdown","metadata":{"id":"QkaAVVFxpgO6"},"source":["## [1] Jaccard similarity 를 이용한 Content-based filtering\n","\n","### Jaccard similarity\n","\n","split을 이용하여 자카드 유사도를 구하고 유사한 책을 산출해보겠습니다.\n","\n","먼저 set을 이용해서 집합계산을 하는 방식을 살펴보겠습니다.\n","\n","<b>Jaccard similarity 공식</b>\n","\n","![image](https://user-images.githubusercontent.com/77526788/185778489-805cd3e6-1096-487c-b92a-dcca7d76e55a.png)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1677656558506,"user":{"displayName":"강진영","userId":"15199531416785753238"},"user_tz":-540},"id":"fR5tphe2G-F7","outputId":"6b3e460e-6f60-45a7-cee9-d986f3a6ab9a"},"outputs":[{"name":"stdout","output_type":"stream","text":["a:  {'I', 'like', 'banana'}\n","b:  {'I', 'apple', 'like'}\n","intersection:  {'I', 'like'}\n","jaccard similarity 0.5\n"]}],"source":["a = set('I like banana'.split())\n","b = set('I like apple'.split())\n","c = a.intersection(b)\n","\n","jaccard = len(c) / (len(a) + len(b) - len(c))\n","\n","print('a: ', a)\n","print('b: ', b)\n","print('intersection: ', c)\n","print('jaccard similarity', jaccard)"]},{"cell_type":"markdown","metadata":{"id":"sve92_bEcokN"},"source":["\n","이제 book 데이터에 적용하여 유사한 책을 찾아보겠습니다.\n","\n","자카드 유사도는 단어의 빈도수를 고려하지 않기 때문에 unique한 값을 뽑아낸 book_title_list 를 활용하여 진행하겠습니다.\n"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"-Vqisr5B--g9"},"outputs":[],"source":["# title을 기반으로 제목의 유사성을 기반으로 추천을 해보겠습니다.\n","# title을 넣으면, book title list과 자카드 유사도를 구한다.\n","def content_based_filtering_jaccard(book_title_list: list, title: str, topn: Optional[int]=None) -> pd.DataFrame:\n","    topn = 11 if topn is None else topn + 1\n","    target_split_set = set(title.split()) # title은 text 정보이므로 다 끊어서 set으로 만들어줍니다.\n","    sim_list = []\n","    \n","    # book_title col만 있는 df\n","    sim_df = pd.DataFrame(book_title_list, columns=['book_title'])\n","    \n","    # 모든 책 제목을 순회.\n","    for idx, book in enumerate(book_title_list):\n","        title_split_set = set(book.split()) # book_title_list도 마찬가지로 다 끊어서 set으로 만들어줍니다.\n","        title_intersection = target_split_set.intersection(title_split_set)\n","        jac_sim = float(len(title_intersection)) / (len(target_split_set) + len(title_split_set) - len(title_intersection))\n","        sim_list.append(jac_sim) # title과 낱개의 book_title_list와의 자카드 유사도를 저장합니다.[]\n","\n","    \n","    sim_df['jaccard_similarity'] = sim_list\n","    \n","    return sim_df.sort_values('jaccard_similarity', ascending=False).reset_index(drop=True)[1:topn]"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1677656563322,"user":{"displayName":"강진영","userId":"15199531416785753238"},"user_tz":-540},"id":"0n36WtvE--eD","outputId":"a6a6bfb2-fd4a-4f80-83b0-e1e42cf70b96"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>book_title</th>\n","      <th>jaccard_similarity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>Harry Potter and the Prisoner of Azkaban (Book 3)</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Harry Potter and the Goblet of Fire (Book 4)</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Harry Potter and the Sorcerer's Stone (Book 1)</td>\n","      <td>0.416667</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Harry Potter and the Sorcerer's Stone (Harry P...</td>\n","      <td>0.307692</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Secrets of the Morning (Cutler)</td>\n","      <td>0.272727</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                          book_title  jaccard_similarity\n","1  Harry Potter and the Prisoner of Azkaban (Book 3)            0.500000\n","2       Harry Potter and the Goblet of Fire (Book 4)            0.500000\n","3     Harry Potter and the Sorcerer's Stone (Book 1)            0.416667\n","4  Harry Potter and the Sorcerer's Stone (Harry P...            0.307692\n","5                    Secrets of the Morning (Cutler)            0.272727"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["content_based_filtering_jaccard(book_title_list, 'Harry Potter and the Chamber of Secrets (Book 2)', 5)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"0yTwp8kXipVU"},"source":["## [2] TF-IDF 를 이용한 텍스트 데이터 vectorization\n","\n","책 제목 `book_title`에 TF-IDF를 적용하여 벡터화해보겠습니다.\n","\n","우리가 앞서 TF-IDF를 설명할때는 가장 기본적인 식을 기준으로 설명했습니다. \n","\n","그러나 실제로는 기본 식에서 조금 조정된 식을 사용합니다.\n","\n","오늘 실습은 간단하게 Sklearn에 있는 `TfidfVectorizer`함수를 활용해서 진행하겠습니다. \n","\n","Sklearn의 TfidVectorizer 함수는 L2 정규화를 통해 값을 조정하기 때문에 직접 계산한 값과는 차이가 있습니다.\n","\n","본 데이터에 적용하기 앞서 함수의 실행결과를 간단히 살펴보겠습니다."]},{"cell_type":"code","execution_count":36,"metadata":{"id":"RcbeLeH5ioKx"},"outputs":[],"source":["from sklearn.feature_extraction.text import TfidfVectorizer"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>and</th>\n","      <th>be</th>\n","      <th>edgar</th>\n","      <th>good</th>\n","      <th>king</th>\n","      <th>lion</th>\n","      <th>mines</th>\n","      <th>opposites</th>\n","      <th>solomon</th>\n","      <th>the</th>\n","      <th>wardrobe</th>\n","      <th>who</th>\n","      <th>witch</th>\n","      <th>would</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>The Lion, the Witch, and the Wardrobe</th>\n","      <td>0.333301</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.212742</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.788335</td>\n","      <td>0.333301</td>\n","      <td>0.000000</td>\n","      <td>0.333301</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>Lion King Opposites</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.473804</td>\n","      <td>0.473804</td>\n","      <td>0.000000</td>\n","      <td>0.742306</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>Edgar the Lion Who Would Be a Good King</th>\n","      <td>0.000000</td>\n","      <td>0.394165</td>\n","      <td>0.394165</td>\n","      <td>0.394165</td>\n","      <td>0.251590</td>\n","      <td>0.251590</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.310764</td>\n","      <td>0.000000</td>\n","      <td>0.394165</td>\n","      <td>0.000000</td>\n","      <td>0.394165</td>\n","    </tr>\n","    <tr>\n","      <th>King Solomon's Mines</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.411378</td>\n","      <td>0.000000</td>\n","      <td>0.644503</td>\n","      <td>0.000000</td>\n","      <td>0.644503</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              and        be     edgar  \\\n","The Lion, the Witch, and the Wardrobe    0.333301  0.000000  0.000000   \n","Lion King Opposites                      0.000000  0.000000  0.000000   \n","Edgar the Lion Who Would Be a Good King  0.000000  0.394165  0.394165   \n","King Solomon's Mines                     0.000000  0.000000  0.000000   \n","\n","                                             good      king      lion  \\\n","The Lion, the Witch, and the Wardrobe    0.000000  0.000000  0.212742   \n","Lion King Opposites                      0.000000  0.473804  0.473804   \n","Edgar the Lion Who Would Be a Good King  0.394165  0.251590  0.251590   \n","King Solomon's Mines                     0.000000  0.411378  0.000000   \n","\n","                                            mines  opposites   solomon  \\\n","The Lion, the Witch, and the Wardrobe    0.000000   0.000000  0.000000   \n","Lion King Opposites                      0.000000   0.742306  0.000000   \n","Edgar the Lion Who Would Be a Good King  0.000000   0.000000  0.000000   \n","King Solomon's Mines                     0.644503   0.000000  0.644503   \n","\n","                                              the  wardrobe       who  \\\n","The Lion, the Witch, and the Wardrobe    0.788335  0.333301  0.000000   \n","Lion King Opposites                      0.000000  0.000000  0.000000   \n","Edgar the Lion Who Would Be a Good King  0.310764  0.000000  0.394165   \n","King Solomon's Mines                     0.000000  0.000000  0.000000   \n","\n","                                            witch     would  \n","The Lion, the Witch, and the Wardrobe    0.333301  0.000000  \n","Lion King Opposites                      0.000000  0.000000  \n","Edgar the Lion Who Would Be a Good King  0.000000  0.394165  \n","King Solomon's Mines                     0.000000  0.000000  "]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["title_example = [\"The Lion, the Witch, and the Wardrobe\",\n","                \"Lion King Opposites\",\n","                \"Edgar the Lion Who Would Be a Good King\",\n","                \"King Solomon's Mines\"]\n","tfidf = TfidfVectorizer()\n","# 각 TF-idf 를 계산합니다.\n","# print(tfidf.vocabulary_) #각 단어의 인덱스가 어떻게 부여되었는지 보여줍니다.\n","\n","pd.DataFrame(tfidf.fit_transform(title_example).toarray(), columns=tfidf.get_feature_names_out(), index=title_example)"]},{"cell_type":"markdown","metadata":{"id":"hmUSiUFEFJOr"},"source":["## [3] 다양한 유사도 계산을 활용한 Content-based filtering\n","\n","### Euclidean Similarity\n","\n","book.csv의 book_title 을 TF-IDF로 만들어진 벡터를 이용해 변환하겠습니다. \n","그리고 유클리드 유사도를 이용해 유사한 책을 찾아보도록 하겠습니다.\n","\n","![image](https://user-images.githubusercontent.com/77526788/185792355-6b77d980-d153-42a9-9173-f8e3e7442c75.png)"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"NbO2_o1PwHrO"},"outputs":[],"source":["tfidf = TfidfVectorizer()\n","wordmatrix = tfidf.fit_transform(book_title_list).toarray() #책 제목 리스트를 TF-IDF를 활용해 벡터라이징 합니다."]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1677656573635,"user":{"displayName":"강진영","userId":"15199531416785753238"},"user_tz":-540},"id":"dDKFpj3eeRPJ","outputId":"7fad6d8c-3b94-46d8-ea51-ee7004e1c0c4"},"outputs":[{"data":{"text/plain":["array([[0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       ...,\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.]])"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["wordmatrix"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1677656574787,"user":{"displayName":"강진영","userId":"15199531416785753238"},"user_tz":-540},"id":"MJ6hK7rhwsa2","outputId":"0bf297e1-b355-4e43-f103-7207f49a345a"},"outputs":[{"data":{"text/plain":["(916, 1528)"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["wordmatrix.shape # (책 갯수, 단어 갯수)"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"LKIGD0YwFhvQ"},"outputs":[],"source":["from sklearn.metrics.pairwise import euclidean_distances"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"Mv-RNjmAk4aU"},"outputs":[],"source":["# 계산한 유사도를 활용하여 책을 추천해보겠습니다.\n","# wordmatrix는 책 제목을 vectorization 한 array 입니다.\n","def content_based_filtering_euclidean(book_title_list: list, \n","                    wordmatrix: np.array, \n","                    title: str,\n","                    topn: Optional[int]=None) -> pd.DataFrame:\n","    \n","    topn=11 if topn is None else topn+1\n","    \n","    # row간의 유클리드 거리를 계산합니다. wordmatrix.shape이 (916, 1528)이므로 (916, 916) shape이 나옴.\n","    sim_matrix = pd.DataFrame(euclidean_distances(wordmatrix), index=book_title_list, columns=book_title_list)\n","    \n","    target_similarity_df = sim_matrix[title].reset_index().copy()\n","    target_similarity_df.columns=['title', 'euclidean_similarity']\n","    \n","    # 왜 내림차순? 유클리디안 거리를 기준으로 했으니 거리가 짧을 수록 비슷한 것!\n","    # 1부터? -> 자기 자신 제거\n","    # topn까지 추출.\n","    return target_similarity_df.sort_values('euclidean_similarity', ascending=True).reset_index(drop=True)[1:topn] "]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1677656577124,"user":{"displayName":"강진영","userId":"15199531416785753238"},"user_tz":-540},"id":"wvk5wi7FFhp3","outputId":"21583b79-7ed0-41b0-a780-a4f9272cd8f4"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>euclidean_similarity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>Harry Potter and the Goblet of Fire (Book 4)</td>\n","      <td>0.930860</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Harry Potter and the Sorcerer's Stone (Harry P...</td>\n","      <td>0.932147</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Harry Potter and the Prisoner of Azkaban (Book 3)</td>\n","      <td>0.951877</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Harry Potter and the Sorcerer's Stone (Book 1)</td>\n","      <td>0.953682</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>The Chamber</td>\n","      <td>0.991023</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               title  euclidean_similarity\n","1       Harry Potter and the Goblet of Fire (Book 4)              0.930860\n","2  Harry Potter and the Sorcerer's Stone (Harry P...              0.932147\n","3  Harry Potter and the Prisoner of Azkaban (Book 3)              0.951877\n","4     Harry Potter and the Sorcerer's Stone (Book 1)              0.953682\n","5                                        The Chamber              0.991023"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["content_based_filtering_euclidean(book_title_list, wordmatrix, 'Harry Potter and the Chamber of Secrets (Book 2)',5)"]},{"cell_type":"markdown","metadata":{"id":"efJc7EbPlWrp"},"source":["### Cosine Similarity\n","각도 기반으로 주어진 벡터들 사이에 유사도를 계산합니다.\n","\n","sklearn의 `cosine_similarity`를 import하여 계산하겠습니다. \n","\n","![image](https://user-images.githubusercontent.com/77526788/185777726-f8fcb835-933d-4760-af03-50c4edbd0148.png)"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"VVZ1zjQOyErO"},"outputs":[],"source":["from sklearn.metrics.pairwise import cosine_similarity"]},{"cell_type":"code","execution_count":45,"metadata":{"id":"CbEuyZ3llVVS"},"outputs":[],"source":["#코사인 유사도 계산를 content_based_filtering 결과\n","def content_based_filtering_cosin(book_title_list: list,\n","                wordmatrix: np.array, \n","                title: str,\n","                topn: Optional[int]=None) -> pd.DataFrame:\n","    topn=11 if topn is None else topn+1\n","    \n","    # 책-책의 유사도\n","    sim_matrix = pd.DataFrame(cosine_similarity(wordmatrix), index=book_title_list, columns=book_title_list)\n","    target_similarity_df = sim_matrix[title].reset_index().copy()\n","    target_similarity_df.columns=['title', 'cosine_similarity']\n","    return target_similarity_df.sort_values('cosine_similarity', ascending=False).reset_index(drop=True)[1:topn]"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1677656582673,"user":{"displayName":"강진영","userId":"15199531416785753238"},"user_tz":-540},"id":"mjfqeRw3oPbL","outputId":"12b7bdb0-bf66-4926-a8de-de815ca03dec"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>cosine_similarity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>Harry Potter and the Goblet of Fire (Book 4)</td>\n","      <td>0.566749</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Harry Potter and the Sorcerer's Stone (Harry P...</td>\n","      <td>0.565551</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Harry Potter and the Prisoner of Azkaban (Book 3)</td>\n","      <td>0.546965</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Harry Potter and the Sorcerer's Stone (Book 1)</td>\n","      <td>0.545245</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>The Chamber</td>\n","      <td>0.508936</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               title  cosine_similarity\n","1       Harry Potter and the Goblet of Fire (Book 4)           0.566749\n","2  Harry Potter and the Sorcerer's Stone (Harry P...           0.565551\n","3  Harry Potter and the Prisoner of Azkaban (Book 3)           0.546965\n","4     Harry Potter and the Sorcerer's Stone (Book 1)           0.545245\n","5                                        The Chamber           0.508936"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["content_based_filtering_cosin(book_title_list, wordmatrix, 'Harry Potter and the Chamber of Secrets (Book 2)', 5)"]},{"cell_type":"markdown","metadata":{"id":"spEZ7lSyqJKp"},"source":["### 피어슨 상관 계수\n","같은 방식으로 피어슨 상관 계수를 활용해서 추천 결과를 도출해보겠습니다.\n","\n","피어슨 상관 계수 공식은 다음과 같습니다.\n","\n","![image](https://user-images.githubusercontent.com/77526788/185777732-7eefa50e-54e4-474b-9639-c41598210128.png)"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"-n5xFrmVotXT"},"outputs":[],"source":["def content_based_filtering_pearson(book_title_list: list,\n","                                    wordmatrix: np.array, \n","                                    title: str,\n","                                    topn: Optional[int]=None) -> pd.DataFrame:\n","    topn=11 if topn is None else topn+1\n","    sim_matrix = pd.DataFrame(wordmatrix, index=book_title_list).T.corr(method='pearson')\n","    target_similarity_df = sim_matrix[title].reset_index().copy()\n","    target_similarity_df.columns=['title', 'pearson_similarity']\n","    return target_similarity_df.sort_values('pearson_similarity', ascending=False).reset_index(drop=True)[1:topn]"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":4048,"status":"ok","timestamp":1677656590489,"user":{"displayName":"강진영","userId":"15199531416785753238"},"user_tz":-540},"id":"vGT6zgjoqyAO","outputId":"5d4e76d4-2450-4515-e07a-9915bd22e0c7"},"outputs":[],"source":["# 오래 걸림\n","content_based_filtering_pearson(book_title_list, wordmatrix, 'Harry Potter and the Chamber of Secrets (Book 2)', 5)"]},{"cell_type":"markdown","metadata":{"id":"_XJcBHZlHmQl"},"source":["### test set 적용\n","\n","train-test set으로 데이터를 나누고 content-based filering을 통해 RMSE를 구해보겠습니다.\n","\n","코사인 유사도를 적용하는 과정에서 아이템 간의 유사도가 0으로 나와서 나누기를 할 수 없는 문제점이 있습니다.\n","\n","따라서 아주 작은 수(1e-10)를 더해서 이 문제를 해결하겠습니다."]},{"cell_type":"code","execution_count":32,"metadata":{"id":"IBM-cUxV0jd9"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"pgpAVVsUVWwN"},"outputs":[],"source":["train_df, test_df = train_test_split(df, test_size=0.1, random_state=42)"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1677656590490,"user":{"displayName":"강진영","userId":"15199531416785753238"},"user_tz":-540},"id":"dXAX6oVG06cl","outputId":"df2fdb13-3a0f-4f2b-a38a-5ca9f0da295f"},"outputs":[{"name":"stdout","output_type":"stream","text":["train:  (50661, 10)\n","test:  (5629, 10)\n"]}],"source":["print('train: ', train_df.shape)\n","print('test: ',test_df.shape)"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"5uwr4mq3H1mb"},"outputs":[{"ename":"NameError","evalue":"name 'TfidfVectorizer' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[35], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m book_title_train_list \u001b[39m=\u001b[39m train_df[\u001b[39m'\u001b[39m\u001b[39mbook_title\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39munique()\n\u001b[0;32m----> 2\u001b[0m tfidf \u001b[39m=\u001b[39m TfidfVectorizer()\n\u001b[1;32m      3\u001b[0m wordmatrix \u001b[39m=\u001b[39m tfidf\u001b[39m.\u001b[39mfit_transform(book_title_train_list)\u001b[39m.\u001b[39mtoarray() \u001b[39m#책 제목 리스트를 TF-IDF를 활용해 벡터라이징 합니다.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m sim_matrix \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(cosine_similarity(wordmatrix), index\u001b[39m=\u001b[39mbook_title_train_list, columns\u001b[39m=\u001b[39mbook_title_train_list)\n","\u001b[0;31mNameError\u001b[0m: name 'TfidfVectorizer' is not defined"]}],"source":["book_title_train_list = train_df['book_title'].unique()\n","tfidf = TfidfVectorizer()\n","wordmatrix = tfidf.fit_transform(book_title_train_list).toarray() #책 제목 리스트를 TF-IDF를 활용해 벡터라이징 합니다.\n","sim_matrix = pd.DataFrame(cosine_similarity(wordmatrix), index=book_title_train_list, columns=book_title_train_list) #벡터간 유사도 계산"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":641},"executionInfo":{"elapsed":368,"status":"ok","timestamp":1677656597649,"user":{"displayName":"강진영","userId":"15199531416785753238"},"user_tz":-540},"id":"rG8gCGsCH1j3","outputId":"afcebc41-030e-4754-d58a-5b155a531a21"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>The Third Victim</th>\n","      <th>Chicken Soup for the Pet Lover's Soul (Chicken Soup for the Soul)</th>\n","      <th>A Is for Alibi (Kinsey Millhone Mysteries (Paperback))</th>\n","      <th>The Valley of Horses</th>\n","      <th>A Year in Provence</th>\n","      <th>Voyager</th>\n","      <th>The Perfect Storm : A True Story of Men Against the Sea</th>\n","      <th>Divine Secrets of the Ya-Ya Sisterhood: A Novel</th>\n","      <th>Tell Me Lies (Tell Me Lies)</th>\n","      <th>The Prince of Tides</th>\n","      <th>...</th>\n","      <th>Hearts In Atlantis : New Fiction</th>\n","      <th>Balzac and the Little Chinese Seamstress</th>\n","      <th>Shipping News</th>\n","      <th>The Outsiders (Now in Speak!)</th>\n","      <th>Memoirs of a Geisha Uk</th>\n","      <th>Isle of Dogs</th>\n","      <th>Gap Creek: The Story Of A Marriage</th>\n","      <th>The Perks of Being a Wallflower</th>\n","      <th>Notes From a Small Planet</th>\n","      <th>Horse Whisperer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>The Third Victim</th>\n","      <td>1.000000</td>\n","      <td>0.030328</td>\n","      <td>0.000000</td>\n","      <td>0.035998</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.042374</td>\n","      <td>0.020639</td>\n","      <td>0.0</td>\n","      <td>0.036985</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.025994</td>\n","      <td>0.0</td>\n","      <td>0.029280</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.028829</td>\n","      <td>0.029112</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>Chicken Soup for the Pet Lover's Soul (Chicken Soup for the Soul)</th>\n","      <td>0.030328</td>\n","      <td>1.000000</td>\n","      <td>0.103626</td>\n","      <td>0.029325</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.034519</td>\n","      <td>0.016813</td>\n","      <td>0.0</td>\n","      <td>0.030129</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.021175</td>\n","      <td>0.0</td>\n","      <td>0.023852</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.023485</td>\n","      <td>0.023715</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>A Is for Alibi (Kinsey Millhone Mysteries (Paperback))</th>\n","      <td>0.000000</td>\n","      <td>0.103626</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>The Valley of Horses</th>\n","      <td>0.035998</td>\n","      <td>0.029325</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.079253</td>\n","      <td>0.057246</td>\n","      <td>0.0</td>\n","      <td>0.102586</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.025134</td>\n","      <td>0.0</td>\n","      <td>0.028312</td>\n","      <td>0.055907</td>\n","      <td>0.064468</td>\n","      <td>0.079963</td>\n","      <td>0.080747</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>A Year in Provence</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.118786</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.123219</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>Isle of Dogs</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.064468</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.037943</td>\n","      <td>0.036961</td>\n","      <td>0.0</td>\n","      <td>0.066235</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.055414</td>\n","      <td>1.000000</td>\n","      <td>0.051629</td>\n","      <td>0.052135</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>Gap Creek: The Story Of A Marriage</th>\n","      <td>0.028829</td>\n","      <td>0.023485</td>\n","      <td>0.000000</td>\n","      <td>0.079963</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.198066</td>\n","      <td>0.045845</td>\n","      <td>0.0</td>\n","      <td>0.082156</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.020128</td>\n","      <td>0.0</td>\n","      <td>0.022674</td>\n","      <td>0.044773</td>\n","      <td>0.051629</td>\n","      <td>1.000000</td>\n","      <td>0.064666</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>The Perks of Being a Wallflower</th>\n","      <td>0.029112</td>\n","      <td>0.023715</td>\n","      <td>0.000000</td>\n","      <td>0.080747</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.064092</td>\n","      <td>0.046295</td>\n","      <td>0.0</td>\n","      <td>0.082961</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.020326</td>\n","      <td>0.0</td>\n","      <td>0.022896</td>\n","      <td>0.045212</td>\n","      <td>0.052135</td>\n","      <td>0.064666</td>\n","      <td>1.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>Notes From a Small Planet</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>Horse Whisperer</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>916 rows × 916 columns</p>\n","</div>"],"text/plain":["                                                    The Third Victim  \\\n","The Third Victim                                            1.000000   \n","Chicken Soup for the Pet Lover's Soul (Chicken ...          0.030328   \n","A Is for Alibi (Kinsey Millhone Mysteries (Pape...          0.000000   \n","The Valley of Horses                                        0.035998   \n","A Year in Provence                                          0.000000   \n","...                                                              ...   \n","Isle of Dogs                                                0.000000   \n","Gap Creek: The Story Of A Marriage                          0.028829   \n","The Perks of Being a Wallflower                             0.029112   \n","Notes From a Small Planet                                   0.000000   \n","Horse Whisperer                                             0.000000   \n","\n","                                                    Chicken Soup for the Pet Lover's Soul (Chicken Soup for the Soul)  \\\n","The Third Victim                                                                             0.030328                   \n","Chicken Soup for the Pet Lover's Soul (Chicken ...                                           1.000000                   \n","A Is for Alibi (Kinsey Millhone Mysteries (Pape...                                           0.103626                   \n","The Valley of Horses                                                                         0.029325                   \n","A Year in Provence                                                                           0.000000                   \n","...                                                                                               ...                   \n","Isle of Dogs                                                                                 0.000000                   \n","Gap Creek: The Story Of A Marriage                                                           0.023485                   \n","The Perks of Being a Wallflower                                                              0.023715                   \n","Notes From a Small Planet                                                                    0.000000                   \n","Horse Whisperer                                                                              0.000000                   \n","\n","                                                    A Is for Alibi (Kinsey Millhone Mysteries (Paperback))  \\\n","The Third Victim                                                                             0.000000        \n","Chicken Soup for the Pet Lover's Soul (Chicken ...                                           0.103626        \n","A Is for Alibi (Kinsey Millhone Mysteries (Pape...                                           1.000000        \n","The Valley of Horses                                                                         0.000000        \n","A Year in Provence                                                                           0.000000        \n","...                                                                                               ...        \n","Isle of Dogs                                                                                 0.000000        \n","Gap Creek: The Story Of A Marriage                                                           0.000000        \n","The Perks of Being a Wallflower                                                              0.000000        \n","Notes From a Small Planet                                                                    0.000000        \n","Horse Whisperer                                                                              0.000000        \n","\n","                                                    The Valley of Horses  \\\n","The Third Victim                                                0.035998   \n","Chicken Soup for the Pet Lover's Soul (Chicken ...              0.029325   \n","A Is for Alibi (Kinsey Millhone Mysteries (Pape...              0.000000   \n","The Valley of Horses                                            1.000000   \n","A Year in Provence                                              0.000000   \n","...                                                                  ...   \n","Isle of Dogs                                                    0.064468   \n","Gap Creek: The Story Of A Marriage                              0.079963   \n","The Perks of Being a Wallflower                                 0.080747   \n","Notes From a Small Planet                                       0.000000   \n","Horse Whisperer                                                 0.000000   \n","\n","                                                    A Year in Provence  \\\n","The Third Victim                                                   0.0   \n","Chicken Soup for the Pet Lover's Soul (Chicken ...                 0.0   \n","A Is for Alibi (Kinsey Millhone Mysteries (Pape...                 0.0   \n","The Valley of Horses                                               0.0   \n","A Year in Provence                                                 1.0   \n","...                                                                ...   \n","Isle of Dogs                                                       0.0   \n","Gap Creek: The Story Of A Marriage                                 0.0   \n","The Perks of Being a Wallflower                                    0.0   \n","Notes From a Small Planet                                          0.0   \n","Horse Whisperer                                                    0.0   \n","\n","                                                    Voyager  \\\n","The Third Victim                                        0.0   \n","Chicken Soup for the Pet Lover's Soul (Chicken ...      0.0   \n","A Is for Alibi (Kinsey Millhone Mysteries (Pape...      0.0   \n","The Valley of Horses                                    0.0   \n","A Year in Provence                                      0.0   \n","...                                                     ...   \n","Isle of Dogs                                            0.0   \n","Gap Creek: The Story Of A Marriage                      0.0   \n","The Perks of Being a Wallflower                         0.0   \n","Notes From a Small Planet                               0.0   \n","Horse Whisperer                                         0.0   \n","\n","                                                    The Perfect Storm : A True Story of Men Against the Sea  \\\n","The Third Victim                                                                             0.042374         \n","Chicken Soup for the Pet Lover's Soul (Chicken ...                                           0.034519         \n","A Is for Alibi (Kinsey Millhone Mysteries (Pape...                                           0.000000         \n","The Valley of Horses                                                                         0.079253         \n","A Year in Provence                                                                           0.000000         \n","...                                                                                               ...         \n","Isle of Dogs                                                                                 0.037943         \n","Gap Creek: The Story Of A Marriage                                                           0.198066         \n","The Perks of Being a Wallflower                                                              0.064092         \n","Notes From a Small Planet                                                                    0.000000         \n","Horse Whisperer                                                                              0.000000         \n","\n","                                                    Divine Secrets of the Ya-Ya Sisterhood: A Novel  \\\n","The Third Victim                                                                           0.020639   \n","Chicken Soup for the Pet Lover's Soul (Chicken ...                                         0.016813   \n","A Is for Alibi (Kinsey Millhone Mysteries (Pape...                                         0.000000   \n","The Valley of Horses                                                                       0.057246   \n","A Year in Provence                                                                         0.000000   \n","...                                                                                             ...   \n","Isle of Dogs                                                                               0.036961   \n","Gap Creek: The Story Of A Marriage                                                         0.045845   \n","The Perks of Being a Wallflower                                                            0.046295   \n","Notes From a Small Planet                                                                  0.000000   \n","Horse Whisperer                                                                            0.000000   \n","\n","                                                    Tell Me Lies (Tell Me Lies)  \\\n","The Third Victim                                                            0.0   \n","Chicken Soup for the Pet Lover's Soul (Chicken ...                          0.0   \n","A Is for Alibi (Kinsey Millhone Mysteries (Pape...                          0.0   \n","The Valley of Horses                                                        0.0   \n","A Year in Provence                                                          0.0   \n","...                                                                         ...   \n","Isle of Dogs                                                                0.0   \n","Gap Creek: The Story Of A Marriage                                          0.0   \n","The Perks of Being a Wallflower                                             0.0   \n","Notes From a Small Planet                                                   0.0   \n","Horse Whisperer                                                             0.0   \n","\n","                                                    The Prince of Tides  ...  \\\n","The Third Victim                                               0.036985  ...   \n","Chicken Soup for the Pet Lover's Soul (Chicken ...             0.030129  ...   \n","A Is for Alibi (Kinsey Millhone Mysteries (Pape...             0.000000  ...   \n","The Valley of Horses                                           0.102586  ...   \n","A Year in Provence                                             0.000000  ...   \n","...                                                                 ...  ...   \n","Isle of Dogs                                                   0.066235  ...   \n","Gap Creek: The Story Of A Marriage                             0.082156  ...   \n","The Perks of Being a Wallflower                                0.082961  ...   \n","Notes From a Small Planet                                      0.000000  ...   \n","Horse Whisperer                                                0.000000  ...   \n","\n","                                                    Hearts In Atlantis : New Fiction  \\\n","The Third Victim                                                            0.000000   \n","Chicken Soup for the Pet Lover's Soul (Chicken ...                          0.000000   \n","A Is for Alibi (Kinsey Millhone Mysteries (Pape...                          0.000000   \n","The Valley of Horses                                                        0.000000   \n","A Year in Provence                                                          0.118786   \n","...                                                                              ...   \n","Isle of Dogs                                                                0.000000   \n","Gap Creek: The Story Of A Marriage                                          0.000000   \n","The Perks of Being a Wallflower                                             0.000000   \n","Notes From a Small Planet                                                   0.000000   \n","Horse Whisperer                                                             0.000000   \n","\n","                                                    Balzac and the Little Chinese Seamstress  \\\n","The Third Victim                                                                    0.025994   \n","Chicken Soup for the Pet Lover's Soul (Chicken ...                                  0.021175   \n","A Is for Alibi (Kinsey Millhone Mysteries (Pape...                                  0.000000   \n","The Valley of Horses                                                                0.025134   \n","A Year in Provence                                                                  0.000000   \n","...                                                                                      ...   \n","Isle of Dogs                                                                        0.000000   \n","Gap Creek: The Story Of A Marriage                                                  0.020128   \n","The Perks of Being a Wallflower                                                     0.020326   \n","Notes From a Small Planet                                                           0.000000   \n","Horse Whisperer                                                                     0.000000   \n","\n","                                                    Shipping News  \\\n","The Third Victim                                              0.0   \n","Chicken Soup for the Pet Lover's Soul (Chicken ...            0.0   \n","A Is for Alibi (Kinsey Millhone Mysteries (Pape...            0.0   \n","The Valley of Horses                                          0.0   \n","A Year in Provence                                            0.0   \n","...                                                           ...   \n","Isle of Dogs                                                  0.0   \n","Gap Creek: The Story Of A Marriage                            0.0   \n","The Perks of Being a Wallflower                               0.0   \n","Notes From a Small Planet                                     0.0   \n","Horse Whisperer                                               0.0   \n","\n","                                                    The Outsiders (Now in Speak!)  \\\n","The Third Victim                                                         0.029280   \n","Chicken Soup for the Pet Lover's Soul (Chicken ...                       0.023852   \n","A Is for Alibi (Kinsey Millhone Mysteries (Pape...                       0.000000   \n","The Valley of Horses                                                     0.028312   \n","A Year in Provence                                                       0.123219   \n","...                                                                           ...   \n","Isle of Dogs                                                             0.000000   \n","Gap Creek: The Story Of A Marriage                                       0.022674   \n","The Perks of Being a Wallflower                                          0.022896   \n","Notes From a Small Planet                                                0.000000   \n","Horse Whisperer                                                          0.000000   \n","\n","                                                    Memoirs of a Geisha Uk  \\\n","The Third Victim                                                  0.000000   \n","Chicken Soup for the Pet Lover's Soul (Chicken ...                0.000000   \n","A Is for Alibi (Kinsey Millhone Mysteries (Pape...                0.000000   \n","The Valley of Horses                                              0.055907   \n","A Year in Provence                                                0.000000   \n","...                                                                    ...   \n","Isle of Dogs                                                      0.055414   \n","Gap Creek: The Story Of A Marriage                                0.044773   \n","The Perks of Being a Wallflower                                   0.045212   \n","Notes From a Small Planet                                         0.000000   \n","Horse Whisperer                                                   0.000000   \n","\n","                                                    Isle of Dogs  \\\n","The Third Victim                                        0.000000   \n","Chicken Soup for the Pet Lover's Soul (Chicken ...      0.000000   \n","A Is for Alibi (Kinsey Millhone Mysteries (Pape...      0.000000   \n","The Valley of Horses                                    0.064468   \n","A Year in Provence                                      0.000000   \n","...                                                          ...   \n","Isle of Dogs                                            1.000000   \n","Gap Creek: The Story Of A Marriage                      0.051629   \n","The Perks of Being a Wallflower                         0.052135   \n","Notes From a Small Planet                               0.000000   \n","Horse Whisperer                                         0.000000   \n","\n","                                                    Gap Creek: The Story Of A Marriage  \\\n","The Third Victim                                                              0.028829   \n","Chicken Soup for the Pet Lover's Soul (Chicken ...                            0.023485   \n","A Is for Alibi (Kinsey Millhone Mysteries (Pape...                            0.000000   \n","The Valley of Horses                                                          0.079963   \n","A Year in Provence                                                            0.000000   \n","...                                                                                ...   \n","Isle of Dogs                                                                  0.051629   \n","Gap Creek: The Story Of A Marriage                                            1.000000   \n","The Perks of Being a Wallflower                                               0.064666   \n","Notes From a Small Planet                                                     0.000000   \n","Horse Whisperer                                                               0.000000   \n","\n","                                                    The Perks of Being a Wallflower  \\\n","The Third Victim                                                           0.029112   \n","Chicken Soup for the Pet Lover's Soul (Chicken ...                         0.023715   \n","A Is for Alibi (Kinsey Millhone Mysteries (Pape...                         0.000000   \n","The Valley of Horses                                                       0.080747   \n","A Year in Provence                                                         0.000000   \n","...                                                                             ...   \n","Isle of Dogs                                                               0.052135   \n","Gap Creek: The Story Of A Marriage                                         0.064666   \n","The Perks of Being a Wallflower                                            1.000000   \n","Notes From a Small Planet                                                  0.000000   \n","Horse Whisperer                                                            0.000000   \n","\n","                                                    Notes From a Small Planet  \\\n","The Third Victim                                                          0.0   \n","Chicken Soup for the Pet Lover's Soul (Chicken ...                        0.0   \n","A Is for Alibi (Kinsey Millhone Mysteries (Pape...                        0.0   \n","The Valley of Horses                                                      0.0   \n","A Year in Provence                                                        0.0   \n","...                                                                       ...   \n","Isle of Dogs                                                              0.0   \n","Gap Creek: The Story Of A Marriage                                        0.0   \n","The Perks of Being a Wallflower                                           0.0   \n","Notes From a Small Planet                                                 1.0   \n","Horse Whisperer                                                           0.0   \n","\n","                                                    Horse Whisperer  \n","The Third Victim                                                0.0  \n","Chicken Soup for the Pet Lover's Soul (Chicken ...              0.0  \n","A Is for Alibi (Kinsey Millhone Mysteries (Pape...              0.0  \n","The Valley of Horses                                            0.0  \n","A Year in Provence                                              0.0  \n","...                                                             ...  \n","Isle of Dogs                                                    0.0  \n","Gap Creek: The Story Of A Marriage                              0.0  \n","The Perks of Being a Wallflower                                 0.0  \n","Notes From a Small Planet                                       0.0  \n","Horse Whisperer                                                 1.0  \n","\n","[916 rows x 916 columns]"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["sim_matrix"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"iXJ0E54zKKiE"},"outputs":[],"source":["# test_df 실험해보려고~\n","def content_based_filtering(train_df: pd.DataFrame,\n","                            test_df: pd.DataFrame) -> list:\n","    pred_rating_list = []\n","    \n","    # index, columns, values로 새 matrix(table) 만듦. train_df가 필요해서 그럼\n","    user_item_matrix = train_df.pivot_table(index=['user_id'], columns=['book_title'], values='rating').fillna(0)\n","    \n","    # train_df로 만든 유사도 matrix가 있으니 이걸로 test_df의 데이터들도 예측해보려고 함.\n","    for test_id, test_title in zip(test_df['user_id'], test_df['book_title']):\n","        similarity_list = []\n","        rating_list = []\n","        \n","        # train_df내에서 test_id와 같은 user_id를 가진 책들의 제목을 가져옴\n","        for read_book in train_df[train_df['user_id']==test_id]['book_title']:\n","            \n","            # sim_matrix에서 해당 책의 유사도 가져옴.\n","            similarity_list.append(sim_matrix[read_book][test_title]) \n","            rating_list.append(user_item_matrix[test_title][test_id])\n","        \n","        similarity_list = np.array(similarity_list)\n","        rating_list = np.array(rating_list)\n","        \n","        pred = (similarity_list * rating_list).sum() / (similarity_list.sum() + 1e-10) #분모가 0이되는 것을 방지하기 위해 작은 수를 더합니다.\n","        pred_rating_list.append(pred)\n","        \n","    return pred_rating_list\n"]},{"cell_type":"code","execution_count":45,"metadata":{"id":"oDzhyaSmUVub"},"outputs":[],"source":["pred_rating = content_based_filtering(train_df, test_df)"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1677656625083,"user":{"displayName":"강진영","userId":"15199531416785753238"},"user_tz":-540},"id":"-VducHhgTcKL","outputId":"3317ce87-d49c-41c5-fe5c-46b8c46db3b7"},"outputs":[{"data":{"text/plain":["4.0909885846732745"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["mean_squared_error(test_df['rating'], pred_rating)**0.5"]},{"cell_type":"markdown","metadata":{"id":"5unjygEoqOyI"},"source":["## [4] User based Collaborative Filtering (UBCF)\n","\n","이번에는 User-based CF를 실습해보겠습니다.\n","\n","평점을 기반으로 User-Item matrix를 만들고 코사인 유사도를 이용해 추천 리스트를 만들어 보겠습니다."]},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":810,"status":"ok","timestamp":1677656634817,"user":{"displayName":"강진영","userId":"15199531416785753238"},"user_tz":-540},"id":"37YR-N6UpaKP","outputId":"e47016ba-610f-4b19-b8f8-dccfbec5e518"},"outputs":[{"name":"stdout","output_type":"stream","text":["user_item_matrix shape:  (800, 916)\n"]}],"source":["user_item_matrix = df.pivot_table(index=['user_id'], columns=['book_title'], values='rating')\n","print('user_item_matrix shape: ', user_item_matrix.shape)"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[{"data":{"text/plain":["0.9237813864628821"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["# na이 92%인데...? 매우 많음.\n","user_item_matrix.isna().sum().sum() / (user_item_matrix.shape[0] * user_item_matrix.shape[1])"]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":534},"executionInfo":{"elapsed":568,"status":"ok","timestamp":1677656636855,"user":{"displayName":"강진영","userId":"15199531416785753238"},"user_tz":-540},"id":"FMQO5VS9ei7J","outputId":"52f38dee-9cea-4910-f75c-2b659cbf3316"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th>book_title</th>\n","      <th>1984</th>\n","      <th>1st to Die: A Novel</th>\n","      <th>2010: Odyssey Two</th>\n","      <th>24 Hours</th>\n","      <th>A 2nd Helping of Chicken Soup for the Soul (Chicken Soup for the Soul Series (Paper))</th>\n","      <th>A Beautiful Mind: The Life of Mathematical Genius and Nobel Laureate John Nash</th>\n","      <th>A Bend in the Road</th>\n","      <th>A Case of Need</th>\n","      <th>A Child Called \\It\\\": One Child's Courage to Survive\"</th>\n","      <th>A Civil Action</th>\n","      <th>...</th>\n","      <th>Wifey</th>\n","      <th>Windmills of the Gods</th>\n","      <th>Winter Moon</th>\n","      <th>Winter Solstice</th>\n","      <th>Wish You Well</th>\n","      <th>Wuthering Heights</th>\n","      <th>You Belong To Me</th>\n","      <th>Zen and the Art of Motorcycle Maintenance: An Inquiry into Values</th>\n","      <th>Zoya</th>\n","      <th>\\O\\\" Is for Outlaw\"</th>\n","    </tr>\n","    <tr>\n","      <th>user_id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>243</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>254</th>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>882</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2276</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2766</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>274301</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>8.0</td>\n","    </tr>\n","    <tr>\n","      <th>274308</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>275970</th>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>277427</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>10.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>278418</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>800 rows × 916 columns</p>\n","</div>"],"text/plain":["book_title  1984  1st to Die: A Novel  2010: Odyssey Two  24 Hours  \\\n","user_id                                                              \n","243          NaN                  NaN                NaN       NaN   \n","254          9.0                  NaN                NaN       NaN   \n","882          NaN                  NaN                NaN       NaN   \n","2276         NaN                  NaN                1.0       NaN   \n","2766         NaN                  NaN                NaN       NaN   \n","...          ...                  ...                ...       ...   \n","274301       NaN                  NaN                NaN       NaN   \n","274308       NaN                  NaN                NaN       NaN   \n","275970       1.0                  NaN                NaN       NaN   \n","277427       NaN                  NaN                NaN      10.0   \n","278418       NaN                  NaN                NaN       NaN   \n","\n","book_title  A 2nd Helping of Chicken Soup for the Soul (Chicken Soup for the Soul Series (Paper))  \\\n","user_id                                                                                             \n","243                                                       NaN                                       \n","254                                                       NaN                                       \n","882                                                       NaN                                       \n","2276                                                      NaN                                       \n","2766                                                      NaN                                       \n","...                                                       ...                                       \n","274301                                                    NaN                                       \n","274308                                                    NaN                                       \n","275970                                                    NaN                                       \n","277427                                                    NaN                                       \n","278418                                                    NaN                                       \n","\n","book_title  A Beautiful Mind: The Life of Mathematical Genius and Nobel Laureate John Nash  \\\n","user_id                                                                                      \n","243                                                       NaN                                \n","254                                                       NaN                                \n","882                                                       NaN                                \n","2276                                                      NaN                                \n","2766                                                      NaN                                \n","...                                                       ...                                \n","274301                                                    NaN                                \n","274308                                                    NaN                                \n","275970                                                    NaN                                \n","277427                                                    NaN                                \n","278418                                                    NaN                                \n","\n","book_title  A Bend in the Road  A Case of Need  \\\n","user_id                                          \n","243                        NaN             NaN   \n","254                        1.0             NaN   \n","882                        NaN             NaN   \n","2276                       NaN             NaN   \n","2766                       NaN             1.0   \n","...                        ...             ...   \n","274301                     NaN             NaN   \n","274308                     NaN             NaN   \n","275970                     NaN             NaN   \n","277427                     NaN             NaN   \n","278418                     NaN             1.0   \n","\n","book_title  A Child Called \\It\\\": One Child's Courage to Survive\"  \\\n","user_id                                                             \n","243                                                       NaN       \n","254                                                       NaN       \n","882                                                       NaN       \n","2276                                                      NaN       \n","2766                                                      NaN       \n","...                                                       ...       \n","274301                                                    NaN       \n","274308                                                    NaN       \n","275970                                                    NaN       \n","277427                                                    NaN       \n","278418                                                    NaN       \n","\n","book_title  A Civil Action  ...  Wifey  Windmills of the Gods  Winter Moon  \\\n","user_id                     ...                                              \n","243                    NaN  ...    NaN                    NaN          NaN   \n","254                    NaN  ...    NaN                    1.0          NaN   \n","882                    NaN  ...    NaN                    NaN          NaN   \n","2276                   NaN  ...    NaN                    NaN          NaN   \n","2766                   NaN  ...    NaN                    NaN          NaN   \n","...                    ...  ...    ...                    ...          ...   \n","274301                 NaN  ...    NaN                    NaN          NaN   \n","274308                 NaN  ...    NaN                    NaN          NaN   \n","275970                 NaN  ...    NaN                    NaN          NaN   \n","277427                 NaN  ...    NaN                    NaN          NaN   \n","278418                 NaN  ...    NaN                    1.0          NaN   \n","\n","book_title  Winter Solstice  Wish You Well  Wuthering Heights  \\\n","user_id                                                         \n","243                     NaN            NaN                NaN   \n","254                     NaN            NaN                NaN   \n","882                     NaN            NaN                NaN   \n","2276                    NaN            NaN                NaN   \n","2766                    NaN            NaN                NaN   \n","...                     ...            ...                ...   \n","274301                  NaN            NaN                NaN   \n","274308                  NaN            NaN                NaN   \n","275970                  NaN            NaN                NaN   \n","277427                  NaN            NaN                NaN   \n","278418                  NaN            NaN                NaN   \n","\n","book_title  You Belong To Me  \\\n","user_id                        \n","243                      NaN   \n","254                      NaN   \n","882                      NaN   \n","2276                     NaN   \n","2766                     NaN   \n","...                      ...   \n","274301                   NaN   \n","274308                   NaN   \n","275970                   NaN   \n","277427                   NaN   \n","278418                   NaN   \n","\n","book_title  Zen and the Art of Motorcycle Maintenance: An Inquiry into Values  \\\n","user_id                                                                         \n","243                                                       NaN                   \n","254                                                       NaN                   \n","882                                                       NaN                   \n","2276                                                      NaN                   \n","2766                                                      NaN                   \n","...                                                       ...                   \n","274301                                                    NaN                   \n","274308                                                    NaN                   \n","275970                                                    1.0                   \n","277427                                                    NaN                   \n","278418                                                    NaN                   \n","\n","book_title  Zoya  \\O\\\" Is for Outlaw\"  \n","user_id                                \n","243          NaN                  NaN  \n","254          NaN                  NaN  \n","882          NaN                  NaN  \n","2276         NaN                  NaN  \n","2766         NaN                  NaN  \n","...          ...                  ...  \n","274301       NaN                  8.0  \n","274308       NaN                  NaN  \n","275970       NaN                  NaN  \n","277427       NaN                  NaN  \n","278418       NaN                  NaN  \n","\n","[800 rows x 916 columns]"]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["user_item_matrix"]},{"cell_type":"code","execution_count":50,"metadata":{"id":"q__IjdjgqMIb"},"outputs":[],"source":["#유사도 계산을 위해 NaN값을 0으로 채워줍니다.\n","#앞서 봤듯이 굉장히 sparse함.\n","user_item_matrix = user_item_matrix.fillna(0)"]},{"cell_type":"code","execution_count":51,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":334,"status":"ok","timestamp":1677656639118,"user":{"displayName":"강진영","userId":"15199531416785753238"},"user_tz":-540},"id":"H0eLKIIWqMFU","outputId":"a1086c6e-7a33-40e0-be7c-35ef4241ea09"},"outputs":[{"name":"stdout","output_type":"stream","text":["user_similarity shape:  (800, 800)\n"]}],"source":["#코사인 유사도 계산. \n","# user-user 유사도임. 우리는 지금 ubcf를 하고 있는 거라니까?\n","user_similarity = cosine_similarity(user_item_matrix) \n","\n","print('user_similarity shape: ', user_similarity.shape) # user_item_matrix[0], user_item_matrix[0]이 나옴."]},{"cell_type":"code","execution_count":52,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1677656639506,"user":{"displayName":"강진영","userId":"15199531416785753238"},"user_tz":-540},"id":"5I9QUOvVjokE","outputId":"57c23e48-14cb-404d-a79b-0ae64e47f19d"},"outputs":[{"data":{"text/plain":["array([[1.        , 0.01523286, 0.01788076, ..., 0.01482404, 0.07060269,\n","        0.04671182],\n","       [0.01523286, 1.        , 0.03522542, ..., 0.13414197, 0.04375281,\n","        0.02126757],\n","       [0.01788076, 0.03522542, 1.        , ..., 0.01096961, 0.01935006,\n","        0.04224758],\n","       ...,\n","       [0.01482404, 0.13414197, 0.01096961, ..., 1.        , 0.06082653,\n","        0.06381511],\n","       [0.07060269, 0.04375281, 0.01935006, ..., 0.06082653, 1.        ,\n","        0.01947121],\n","       [0.04671182, 0.02126757, 0.04224758, ..., 0.06381511, 0.01947121,\n","        1.        ]])"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["user_similarity #코사인 유사도를 계산한 결과"]},{"cell_type":"code","execution_count":53,"metadata":{"id":"w0g8P9pJpaFz"},"outputs":[],"source":["def UBCF(df: pd.DataFrame, \n","         user_id: int,\n","         topn: Optional[int]=None) -> pd.DataFrame:\n","\n","    topn=11 if topn is None else topn + 1\n","    if user_id in df['user_id'].values:\n","        user_id = str(user_id)\n","        user_item_matrix = df.pivot_table(index=['user_id'], columns=['book_title'], values='rating')\n","        user_item_matrix = user_item_matrix.fillna(0)\n","        user_similarity_df = pd.DataFrame(cosine_similarity(user_item_matrix), index=user_item_matrix.index.astype(str), columns=user_item_matrix.index.astype(str))\n","        sim_user_df = user_similarity_df[user_id].sort_values(ascending=False).reset_index(drop=False).rename(columns={'index':'user_id', user_id:'similarity'})\n","        print('입력한 사용자 id: ',user_id)\n","        display(sim_user_df[1:topn]) #비슷한 사용자를 보여줍니다\n","    else:\n","        print('사용자 id를 다시 확인해주세요')"]},{"cell_type":"code","execution_count":54,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1677656641413,"user":{"displayName":"강진영","userId":"15199531416785753238"},"user_tz":-540},"id":"vnmPr5K55Dbu","outputId":"9c0e14cf-99f4-48b7-b300-357d58269d68"},"outputs":[{"name":"stdout","output_type":"stream","text":["입력한 사용자 id:  254\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>similarity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>208141</td>\n","      <td>0.557751</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>175003</td>\n","      <td>0.448879</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>36003</td>\n","      <td>0.401443</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>226965</td>\n","      <td>0.386151</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>205735</td>\n","      <td>0.384968</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  user_id  similarity\n","1  208141    0.557751\n","2  175003    0.448879\n","3   36003    0.401443\n","4  226965    0.386151\n","5  205735    0.384968"]},"metadata":{},"output_type":"display_data"}],"source":["UBCF(df, 254, 5) # 254번 유저와 비슷한 유저들을 보여줌."]},{"cell_type":"markdown","metadata":{"id":"RMeAnZcvHY4Z"},"source":["### test set 적용\n","앞서 분리한 train-test set에 적용하여 RMSE를 계산해보겠습니다."]},{"cell_type":"code","execution_count":55,"metadata":{"id":"MqxtC5PaHX2p"},"outputs":[],"source":["def UBCF_predict_rating(train_df: pd.DataFrame,\n","                        test_df: pd.DataFrame) -> list:\n","    rating_list=[]\n","    \n","    # 우리는 ubcf를 해야 하니까 user-user 유사도를 구해야 함.\n","    user_item_matrix = train_df.pivot_table(index=['user_id'], columns=['book_title'], values='rating')\n","    user_item_matrix = user_item_matrix.fillna(0)\n","    user_similarity_df = pd.DataFrame(cosine_similarity(user_item_matrix), index=user_item_matrix.index.astype(str), columns=user_item_matrix.index.astype(str)) # user-user 유사도임. 우리는 지금 ubcf를 하고 있는 거라니까?\n","    user_similarity_df.index = user_similarity_df.index.astype(int)\n","    \n","    # 각 test_id 별로 sum(유사도 * 평점) / sum(유사도)를 구함.\n","    for test_id, test_book_title in zip(test_df['user_id'].astype(str), test_df['book_title']):\n","        pred_rating = (user_similarity_df[test_id].sort_index().values * user_item_matrix[test_book_title].sort_index().values).sum()/(user_similarity_df[test_id].values.sum())\n","        rating_list.append(pred_rating)\n","    return rating_list"]},{"cell_type":"code","execution_count":56,"metadata":{"id":"gqp-pmdWIQQu"},"outputs":[],"source":["rating_list = UBCF_predict_rating(train_df, test_df)"]},{"cell_type":"code","execution_count":57,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1666547841007,"user":{"displayName":"강진영","userId":"15199531416785753238"},"user_tz":-540},"id":"9qCd-XPbIP9t","outputId":"e447a2d6-89e2-496a-ccb5-63f65bb8698b"},"outputs":[{"data":{"text/plain":["3.8697271791718024"]},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":["mean_squared_error(rating_list, test_df['rating'])**0.5"]},{"cell_type":"markdown","metadata":{"id":"v7v1MhLnlaIX"},"source":["## [5] Item based Collaborative Filtering (IBCF)\n","\n","이번에는 Item-based CF를 실습해보겠습니다.\n","\n","평점을 기반으로 User-Item matrix를 만들고 코사인 유사도를 이용해 유사한 책을 추천 해보겠습니다."]},{"cell_type":"code","execution_count":58,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1666547841008,"user":{"displayName":"강진영","userId":"15199531416785753238"},"user_tz":-540},"id":"YRLMrqba3ivu","outputId":"74545571-860a-4a8f-cdb5-31bcf279ef19"},"outputs":[{"name":"stdout","output_type":"stream","text":["user_item_matrix shape:  (916, 800)\n"]}],"source":["# 주의할 점이, IBCF이므로 i-i 유사도를 구해야 함. 그래서 이번엔 index가 book_title로 하였고, sim table도 book-book matrix여야 함.\n","user_item_matrix = df.pivot_table(index=['book_title'], columns=['user_id'],values='rating')\n","print('user_item_matrix shape: ', user_item_matrix.shape)"]},{"cell_type":"code","execution_count":59,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":455},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1666547841008,"user":{"displayName":"강진영","userId":"15199531416785753238"},"user_tz":-540},"id":"vGT5gyWbpF6B","outputId":"edfcacfe-fc20-49ea-f1d0-1c952b90ee06"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th>user_id</th>\n","      <th>243</th>\n","      <th>254</th>\n","      <th>882</th>\n","      <th>2276</th>\n","      <th>2766</th>\n","      <th>3363</th>\n","      <th>3371</th>\n","      <th>4017</th>\n","      <th>5903</th>\n","      <th>6251</th>\n","      <th>...</th>\n","      <th>271705</th>\n","      <th>273086</th>\n","      <th>273979</th>\n","      <th>274004</th>\n","      <th>274061</th>\n","      <th>274301</th>\n","      <th>274308</th>\n","      <th>275970</th>\n","      <th>277427</th>\n","      <th>278418</th>\n","    </tr>\n","    <tr>\n","      <th>book_title</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1984</th>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>10.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1st to Die: A Novel</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2010: Odyssey Two</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>24 Hours</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>10.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>A 2nd Helping of Chicken Soup for the Soul (Chicken Soup for the Soul Series (Paper))</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>Wuthering Heights</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>You Belong To Me</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>Zen and the Art of Motorcycle Maintenance: An Inquiry into Values</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>Zoya</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>\\O\\\" Is for Outlaw\"</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>8.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>916 rows × 800 columns</p>\n","</div>"],"text/plain":["user_id                                             243     254     882     \\\n","book_title                                                                   \n","1984                                                   NaN     9.0     NaN   \n","1st to Die: A Novel                                    NaN     NaN     NaN   \n","2010: Odyssey Two                                      NaN     NaN     NaN   \n","24 Hours                                               NaN     NaN     NaN   \n","A 2nd Helping of Chicken Soup for the Soul (Chi...     NaN     NaN     NaN   \n","...                                                    ...     ...     ...   \n","Wuthering Heights                                      NaN     NaN     NaN   \n","You Belong To Me                                       NaN     NaN     NaN   \n","Zen and the Art of Motorcycle Maintenance: An I...     NaN     NaN     NaN   \n","Zoya                                                   NaN     NaN     NaN   \n","\\O\\\" Is for Outlaw\"                                    NaN     NaN     NaN   \n","\n","user_id                                             2276    2766    3363    \\\n","book_title                                                                   \n","1984                                                   NaN     NaN     NaN   \n","1st to Die: A Novel                                    NaN     NaN     NaN   \n","2010: Odyssey Two                                      1.0     NaN     NaN   \n","24 Hours                                               NaN     NaN     NaN   \n","A 2nd Helping of Chicken Soup for the Soul (Chi...     NaN     NaN     1.0   \n","...                                                    ...     ...     ...   \n","Wuthering Heights                                      NaN     NaN     NaN   \n","You Belong To Me                                       NaN     NaN     NaN   \n","Zen and the Art of Motorcycle Maintenance: An I...     NaN     NaN     1.0   \n","Zoya                                                   NaN     NaN     NaN   \n","\\O\\\" Is for Outlaw\"                                    NaN     NaN     NaN   \n","\n","user_id                                             3371    4017    5903    \\\n","book_title                                                                   \n","1984                                                   NaN     NaN     NaN   \n","1st to Die: A Novel                                    NaN     NaN     NaN   \n","2010: Odyssey Two                                      NaN     NaN     NaN   \n","24 Hours                                               NaN     NaN     NaN   \n","A 2nd Helping of Chicken Soup for the Soul (Chi...     NaN     NaN     NaN   \n","...                                                    ...     ...     ...   \n","Wuthering Heights                                      NaN     NaN     NaN   \n","You Belong To Me                                       NaN     NaN     NaN   \n","Zen and the Art of Motorcycle Maintenance: An I...     NaN     NaN     NaN   \n","Zoya                                                   NaN     NaN     NaN   \n","\\O\\\" Is for Outlaw\"                                    NaN     NaN     NaN   \n","\n","user_id                                             6251    ...  271705  \\\n","book_title                                                  ...           \n","1984                                                   NaN  ...    10.0   \n","1st to Die: A Novel                                    NaN  ...     NaN   \n","2010: Odyssey Two                                      NaN  ...     NaN   \n","24 Hours                                               NaN  ...     NaN   \n","A 2nd Helping of Chicken Soup for the Soul (Chi...     NaN  ...     NaN   \n","...                                                    ...  ...     ...   \n","Wuthering Heights                                      NaN  ...     NaN   \n","You Belong To Me                                       NaN  ...     NaN   \n","Zen and the Art of Motorcycle Maintenance: An I...     1.0  ...     NaN   \n","Zoya                                                   NaN  ...     NaN   \n","\\O\\\" Is for Outlaw\"                                    NaN  ...     NaN   \n","\n","user_id                                             273086  273979  274004  \\\n","book_title                                                                   \n","1984                                                   NaN     NaN     NaN   \n","1st to Die: A Novel                                    NaN     NaN     NaN   \n","2010: Odyssey Two                                      NaN     NaN     NaN   \n","24 Hours                                               NaN     1.0     NaN   \n","A 2nd Helping of Chicken Soup for the Soul (Chi...     NaN     NaN     NaN   \n","...                                                    ...     ...     ...   \n","Wuthering Heights                                      NaN     NaN     NaN   \n","You Belong To Me                                       NaN     NaN     NaN   \n","Zen and the Art of Motorcycle Maintenance: An I...     NaN     NaN     NaN   \n","Zoya                                                   NaN     1.0     NaN   \n","\\O\\\" Is for Outlaw\"                                    NaN     NaN     NaN   \n","\n","user_id                                             274061  274301  274308  \\\n","book_title                                                                   \n","1984                                                   NaN     NaN     NaN   \n","1st to Die: A Novel                                    NaN     NaN     NaN   \n","2010: Odyssey Two                                      NaN     NaN     NaN   \n","24 Hours                                               NaN     NaN     NaN   \n","A 2nd Helping of Chicken Soup for the Soul (Chi...     NaN     NaN     NaN   \n","...                                                    ...     ...     ...   \n","Wuthering Heights                                      NaN     NaN     NaN   \n","You Belong To Me                                       NaN     NaN     NaN   \n","Zen and the Art of Motorcycle Maintenance: An I...     NaN     NaN     NaN   \n","Zoya                                                   NaN     NaN     NaN   \n","\\O\\\" Is for Outlaw\"                                    NaN     8.0     NaN   \n","\n","user_id                                             275970  277427  278418  \n","book_title                                                                  \n","1984                                                   1.0     NaN     NaN  \n","1st to Die: A Novel                                    NaN     NaN     NaN  \n","2010: Odyssey Two                                      NaN     NaN     NaN  \n","24 Hours                                               NaN    10.0     NaN  \n","A 2nd Helping of Chicken Soup for the Soul (Chi...     NaN     NaN     NaN  \n","...                                                    ...     ...     ...  \n","Wuthering Heights                                      NaN     NaN     NaN  \n","You Belong To Me                                       NaN     NaN     NaN  \n","Zen and the Art of Motorcycle Maintenance: An I...     1.0     NaN     NaN  \n","Zoya                                                   NaN     NaN     NaN  \n","\\O\\\" Is for Outlaw\"                                    NaN     NaN     NaN  \n","\n","[916 rows x 800 columns]"]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":["user_item_matrix # 매우 sparse함"]},{"cell_type":"code","execution_count":61,"metadata":{"id":"atSmmkTCnoV6"},"outputs":[],"source":["def IBCF(df: pd.DataFrame, \n","         title: str,\n","         topn: Optional[int]=None) -> pd.DataFrame:\n","    topn=11 if topn is None else topn+1\n","    if title in df['book_title'].values:\n","        user_item_matrix = df.pivot_table(index=['book_title'], columns=['user_id'], values='rating')\n","        user_item_matrix = user_item_matrix.fillna(0)\n","        item_similarity_df = pd.DataFrame(cosine_similarity(user_item_matrix), index= user_item_matrix.index, columns=user_item_matrix.index)\n","        sim_item_df = item_similarity_df[title].sort_values(ascending=False).reset_index().rename(columns={'index':'book_title',title:'similarity'})\n","        print('입력한 책 이름: ',title)\n","        display(sim_item_df[1:topn])\n","    else:\n","        print('책 제목을 다시 확인해주세요')"]},{"cell_type":"code","execution_count":62,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"executionInfo":{"elapsed":334,"status":"ok","timestamp":1666567360699,"user":{"displayName":"강진영","userId":"15199531416785753238"},"user_tz":-540},"id":"4BGhBUUSoj-U","outputId":"3d8fabc0-3d5e-4f95-ef79-c8261956fb7d"},"outputs":[{"name":"stdout","output_type":"stream","text":["입력한 책 이름:  Harry Potter and the Chamber of Secrets (Book 2)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>book_title</th>\n","      <th>similarity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>Harry Potter and the Prisoner of Azkaban (Book 3)</td>\n","      <td>0.596622</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Harry Potter and the Sorcerer's Stone (Harry P...</td>\n","      <td>0.542272</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Harry Potter and the Goblet of Fire (Book 4)</td>\n","      <td>0.491703</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Harry Potter and the Sorcerer's Stone (Book 1)</td>\n","      <td>0.372600</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Bridget Jones's Diary</td>\n","      <td>0.243946</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                          book_title  similarity\n","1  Harry Potter and the Prisoner of Azkaban (Book 3)    0.596622\n","2  Harry Potter and the Sorcerer's Stone (Harry P...    0.542272\n","3       Harry Potter and the Goblet of Fire (Book 4)    0.491703\n","4     Harry Potter and the Sorcerer's Stone (Book 1)    0.372600\n","5                              Bridget Jones's Diary    0.243946"]},"metadata":{},"output_type":"display_data"}],"source":["IBCF(df,'Harry Potter and the Chamber of Secrets (Book 2)', 5)"]},{"cell_type":"markdown","metadata":{"id":"anqwS4gzGZh5"},"source":["### test set 적용\n","\n","앞서 분리해 놓은 train test set에 맞춰서 코드를 수정하고 RMSE를 구해보겠습니다."]},{"cell_type":"code","execution_count":66,"metadata":{"id":"z4oHElvWGYby"},"outputs":[],"source":["def IBCF_predict_rating(train_df: pd.DataFrame, \n","                        test_df: pd.DataFrame) -> list:\n","    rating_list=[]\n","    user_item_matrix = train_df.pivot_table(index=['book_title'], columns=['user_id'], values='rating')\n","    user_item_matrix = user_item_matrix.fillna(0)\n","    item_similarity_df = pd.DataFrame(cosine_similarity(user_item_matrix), index=user_item_matrix.index, columns=user_item_matrix.index)\n","\n","    for test_id, test_book_title in zip(test_df['user_id'], test_df['book_title']):\n","        try:\n","            pred_rating = (item_similarity_df[test_book_title].sort_index().values * user_item_matrix[test_id].sort_index().values).sum() / item_similarity_df[test_book_title].values.sum()\n","        except:\n","            pred_rating=0\n","        rating_list.append(pred_rating)\n","    return rating_list"]},{"cell_type":"code","execution_count":67,"metadata":{"id":"gVvHSx7tGkQr"},"outputs":[],"source":["rating_list = IBCF_predict_rating(train_df, test_df)"]},{"cell_type":"code","execution_count":68,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1666567365619,"user":{"displayName":"강진영","userId":"15199531416785753238"},"user_tz":-540},"id":"3A93pdEMIKla","outputId":"f4f4390c-f6fd-446b-a560-f73cb81206c5"},"outputs":[{"data":{"text/plain":["3.84702556623124"]},"execution_count":68,"metadata":{},"output_type":"execute_result"}],"source":["mean_squared_error(rating_list, test_df['rating'])**0.5"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["실제로 서빙할 때는 추천할 책 뽑아 놓고 '보지 않았던' 책을 추천해줘야 함. 이미 봤는데 유사도 높다고 또 추천해주면 안 사잖아."]},{"cell_type":"markdown","metadata":{"id":"J9w7LTYBmf9p"},"source":["## [6] Kmeans clustering과 IBCF\n","K-means 클러스터링을 실습해보겠습니다.\n","\n","K-means 클러스터링은 가장 가까운 중심점을 갖는 군집에 각 항목을 할당하는 과정을 반복하여 K개의 군집으로 항목을 나누는 알고리즘입니다.\n","\n","![image.png](https://user-images.githubusercontent.com/77526788/223298457-f9482f4f-1d64-4ecd-bd90-83e594f98a5c.png)\n","\n","\n","1. 랜덤하게 초기 중심점 배치\n","2. 각 데이터를 가장 가까운 중심점으로 할당\n","3. 모인 데이터를 바탕으로 중심점 위치 업데이트\n","4. 더 이상 중심점이 업데이트 되지 않을 때까지 2-3 단계 반복\n","\n","유사한 사용자 군집을 구하고 군집내의 유저 데이터를 이용해 추천결과를 도출해 보겠습니다."]},{"cell_type":"code","execution_count":69,"metadata":{"id":"X6ysALJZnH7w"},"outputs":[],"source":["from sklearn.cluster import KMeans\n","import re"]},{"cell_type":"code","execution_count":71,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":390,"status":"ok","timestamp":1666567369506,"user":{"displayName":"강진영","userId":"15199531416785753238"},"user_tz":-540},"id":"RjI37CvTyvG9","outputId":"64803c2f-933d-435d-abea-336e70a1b065"},"outputs":[{"name":"stdout","output_type":"stream","text":["인코딩 결과의 shape:  (56290, 71)\n"]}],"source":["df['category'] = df['category'].apply(lambda x: re.sub('[\\W_]+', ' ', x).strip()) #데이터 category의 대괄호를 풀어줍니다.\n","\n","encoding_df = pd.concat([df, pd.get_dummies(df[['category', 'language']])], axis=1) #카테고리와 언어로 one-hot-encoding을 수행합니다.\n","print('인코딩 결과의 shape: ', encoding_df.shape)"]},{"cell_type":"code","execution_count":72,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":315},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1666567371138,"user":{"displayName":"강진영","userId":"15199531416785753238"},"user_tz":-540},"id":"5Lsz3i6asYLf","outputId":"90808796-747b-434e-f070-8d92c29ad16f"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>category_9</th>\n","      <th>category_Abortion</th>\n","      <th>category_Actors</th>\n","      <th>category_Adulteresses</th>\n","      <th>category_Adultery</th>\n","      <th>category_African American men</th>\n","      <th>category_Aircraft accidents</th>\n","      <th>category_Arctic regions</th>\n","      <th>category_Artificial intelligence</th>\n","      <th>...</th>\n","      <th>category_Pets</th>\n","      <th>category_Rapture Christian eschatology</th>\n","      <th>category_Religion</th>\n","      <th>category_Self Help</th>\n","      <th>category_Social Science</th>\n","      <th>category_Travel</th>\n","      <th>category_Trials Murder</th>\n","      <th>category_True Crime</th>\n","      <th>language_9</th>\n","      <th>language_en</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>34</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>34</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>34</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>34</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>34</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 62 columns</p>\n","</div>"],"text/plain":["   age  category_9  category_Abortion  category_Actors  category_Adulteresses  \\\n","0   34           1                  0                0                      0   \n","1   34           1                  0                0                      0   \n","2   34           0                  0                0                      0   \n","3   34           1                  0                0                      0   \n","4   34           0                  0                0                      0   \n","\n","   category_Adultery  category_African American men  \\\n","0                  0                              0   \n","1                  0                              0   \n","2                  0                              0   \n","3                  0                              0   \n","4                  0                              0   \n","\n","   category_Aircraft accidents  category_Arctic regions  \\\n","0                            0                        0   \n","1                            0                        0   \n","2                            0                        0   \n","3                            0                        0   \n","4                            0                        0   \n","\n","   category_Artificial intelligence  ...  category_Pets  \\\n","0                                 0  ...              0   \n","1                                 0  ...              0   \n","2                                 0  ...              0   \n","3                                 0  ...              0   \n","4                                 0  ...              0   \n","\n","   category_Rapture Christian eschatology  category_Religion  \\\n","0                                       0                  0   \n","1                                       0                  0   \n","2                                       0                  0   \n","3                                       0                  0   \n","4                                       0                  0   \n","\n","   category_Self Help  category_Social Science  category_Travel  \\\n","0                   0                        0                0   \n","1                   0                        0                0   \n","2                   0                        0                0   \n","3                   0                        0                0   \n","4                   0                        0                0   \n","\n","   category_Trials Murder  category_True Crime  language_9  language_en  \n","0                       0                    0           1            0  \n","1                       0                    0           1            0  \n","2                       0                    0           0            1  \n","3                       0                    0           1            0  \n","4                       0                    0           0            1  \n","\n","[5 rows x 62 columns]"]},"execution_count":72,"metadata":{},"output_type":"execute_result"}],"source":["encoding_df.iloc[:,9:].head()"]},{"cell_type":"code","execution_count":73,"metadata":{"id":"a_tM_6vDuhpR"},"outputs":[],"source":["n=3 #군집개수를 정합니다.\n","km = KMeans(n_clusters=n, random_state=42)\n","km.fit(encoding_df.iloc[:, 9:]) #나이, 언어, 책 카테고리로 군집화를 수행하겠습니다.\n","labels = km.labels_\n","\n","encoding_df['label'] = labels"]},{"cell_type":"code","execution_count":74,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":322,"status":"ok","timestamp":1666567388917,"user":{"displayName":"강진영","userId":"15199531416785753238"},"user_tz":-540},"id":"IafZBw2kuuJs","outputId":"e3461530-1c8d-4a40-b592-398dc7236ef2"},"outputs":[{"data":{"text/plain":["0    29466\n","2    13596\n","1    13228\n","Name: label, dtype: int64"]},"execution_count":74,"metadata":{},"output_type":"execute_result"}],"source":["encoding_df['label'].value_counts() #각 클러스터별 데이터 개수를 확인합니다."]},{"cell_type":"markdown","metadata":{"id":"HCqHNR6nwokR"},"source":["군집결과를 확인해 보겠습니다.\n","\n","군집에 따라 평균 나이와 언어 비율에 차이가 있는 것을 확인할 수 있습니다."]},{"cell_type":"code","execution_count":75,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":458,"status":"ok","timestamp":1666567393084,"user":{"displayName":"강진영","userId":"15199531416785753238"},"user_tz":-540},"id":"o4DAINsrt92g","outputId":"ed74752e-cb34-4f5b-e432-e97c150a06ed"},"outputs":[{"data":{"text/plain":["34.76556030679427"]},"execution_count":75,"metadata":{},"output_type":"execute_result"}],"source":["encoding_df[(encoding_df['label']==0)]['age'].mean()"]},{"cell_type":"code","execution_count":76,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":282,"status":"ok","timestamp":1666567401087,"user":{"displayName":"강진영","userId":"15199531416785753238"},"user_tz":-540},"id":"jfFBK1-4vl3F","outputId":"6f8b1965-c483-4406-8d2c-56c7d1a157ef"},"outputs":[{"data":{"text/plain":["50.64008164499546"]},"execution_count":76,"metadata":{},"output_type":"execute_result"}],"source":["encoding_df[(encoding_df['label']==1)]['age'].mean()"]},{"cell_type":"code","execution_count":77,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":317,"status":"ok","timestamp":1666567405816,"user":{"displayName":"강진영","userId":"15199531416785753238"},"user_tz":-540},"id":"iLudhUTkuD-z","outputId":"2e1302f5-cb79-4603-8c18-f932bcf65c52"},"outputs":[{"data":{"text/plain":["25.694248308325978"]},"execution_count":77,"metadata":{},"output_type":"execute_result"}],"source":["encoding_df[(encoding_df['label']==2)]['age'].mean()"]},{"cell_type":"code","execution_count":78,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1666567427912,"user":{"displayName":"강진영","userId":"15199531416785753238"},"user_tz":-540},"id":"uOhT-zv_KMYe","outputId":"a575c73c-04ff-46b0-aa4e-b1a52988c42f"},"outputs":[{"data":{"text/plain":["en    0.665038\n","9     0.334962\n","Name: language, dtype: float64"]},"execution_count":78,"metadata":{},"output_type":"execute_result"}],"source":["encoding_df[(encoding_df['label']==0)]['language'].value_counts(True)"]},{"cell_type":"code","execution_count":79,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":285,"status":"ok","timestamp":1666567417934,"user":{"displayName":"강진영","userId":"15199531416785753238"},"user_tz":-540},"id":"ye4TVr3qvVTw","outputId":"fcacf01d-12e6-41a0-98d3-7b02a432c16a"},"outputs":[{"data":{"text/plain":["en    0.673269\n","9     0.326731\n","Name: language, dtype: float64"]},"execution_count":79,"metadata":{},"output_type":"execute_result"}],"source":["encoding_df[(encoding_df['label']==1)]['language'].value_counts(True)"]},{"cell_type":"code","execution_count":80,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":443,"status":"ok","timestamp":1666567436772,"user":{"displayName":"강진영","userId":"15199531416785753238"},"user_tz":-540},"id":"rz5d71vhKOFj","outputId":"36affbc8-1f05-4d2f-fdaf-6920dcb25387"},"outputs":[{"data":{"text/plain":["en    0.663063\n","9     0.336937\n","Name: language, dtype: float64"]},"execution_count":80,"metadata":{},"output_type":"execute_result"}],"source":["encoding_df[(encoding_df['label']==2)]['language'].value_counts(True)"]},{"cell_type":"markdown","metadata":{"id":"Og0zVnQ1KphK"},"source":["강의 내에 들어간 실습 자료를 제작 당시에 군집 수를 늘려서 군집간의 차이를 보여주었습니다.\n","\n","그러나 군집 수가 늘어나면 한 군집에 속하는 데이터가 작아지고, 유사한 아이템이 없어서 특정 군집에서는 책 추천이 불가능한 단점이 생깁니다.\n","\n","따라서 실습파일에서는 추천 결과를 보여주고 비교하기 위해 군집 갯수를 줄였습니다.\n","\n","군집 개수는 직접 설정해야하는 파라미터이므로 군집 수에 따라 변하는 추천 결과를 확인해 해보실 수 있습니다."]},{"cell_type":"markdown","metadata":{"id":"oiWH4QCZw3VY"},"source":["군집에 따른 IBCF 결과를 확인해보겠습니다.\n","\n","군집에 따라 다른 책을 추천하는 것을 확인할 수 있습니다."]},{"cell_type":"code","execution_count":81,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":381},"executionInfo":{"elapsed":308,"status":"ok","timestamp":1666567439964,"user":{"displayName":"강진영","userId":"15199531416785753238"},"user_tz":-540},"id":"mIivS8WE0mLO","outputId":"86077051-cc3f-4862-e8e4-883c2c392ffc"},"outputs":[{"name":"stdout","output_type":"stream","text":["입력한 책 이름:  Harry Potter and the Chamber of Secrets (Book 2)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>book_title</th>\n","      <th>similarity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>Harry Potter and the Sorcerer's Stone (Harry P...</td>\n","      <td>0.599127</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Harry Potter and the Prisoner of Azkaban (Book 3)</td>\n","      <td>0.502030</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Harry Potter and the Goblet of Fire (Book 4)</td>\n","      <td>0.461835</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Charlotte's Web (Trophy Newbery)</td>\n","      <td>0.374359</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Bridget Jones's Diary</td>\n","      <td>0.318786</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Harry Potter and the Sorcerer's Stone (Book 1)</td>\n","      <td>0.313076</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>The Andromeda Strain</td>\n","      <td>0.282895</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>The Poet</td>\n","      <td>0.281339</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Chicken Soup for the Pet Lover's Soul (Chicken...</td>\n","      <td>0.279968</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Tough Cookie</td>\n","      <td>0.275961</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                           book_title  similarity\n","1   Harry Potter and the Sorcerer's Stone (Harry P...    0.599127\n","2   Harry Potter and the Prisoner of Azkaban (Book 3)    0.502030\n","3        Harry Potter and the Goblet of Fire (Book 4)    0.461835\n","4                    Charlotte's Web (Trophy Newbery)    0.374359\n","5                               Bridget Jones's Diary    0.318786\n","6      Harry Potter and the Sorcerer's Stone (Book 1)    0.313076\n","7                                The Andromeda Strain    0.282895\n","8                                            The Poet    0.281339\n","9   Chicken Soup for the Pet Lover's Soul (Chicken...    0.279968\n","10                                       Tough Cookie    0.275961"]},"metadata":{},"output_type":"display_data"}],"source":["IBCF(encoding_df[encoding_df['label']==0], 'Harry Potter and the Chamber of Secrets (Book 2)' )"]},{"cell_type":"code","execution_count":82,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":381},"executionInfo":{"elapsed":448,"status":"ok","timestamp":1666567442257,"user":{"displayName":"강진영","userId":"15199531416785753238"},"user_tz":-540},"id":"9FPPL_C208Xi","outputId":"2bf0a15e-7335-4a55-c098-dd391380a1ea"},"outputs":[{"name":"stdout","output_type":"stream","text":["입력한 책 이름:  Harry Potter and the Chamber of Secrets (Book 2)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>book_title</th>\n","      <th>similarity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>Harry Potter and the Prisoner of Azkaban (Book 3)</td>\n","      <td>0.696095</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Harry Potter and the Goblet of Fire (Book 4)</td>\n","      <td>0.690532</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>The Perfect Storm : A True Story of Men Agains...</td>\n","      <td>0.489702</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Harry Potter and the Sorcerer's Stone (Harry P...</td>\n","      <td>0.445134</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Carolina Moon</td>\n","      <td>0.403948</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>The Talented Mr. Ripley (Vintage Crime/Black L...</td>\n","      <td>0.399915</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Born in Fire</td>\n","      <td>0.397422</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Zen and the Art of Motorcycle Maintenance: An ...</td>\n","      <td>0.394280</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>The Hobbit : The Enchanting Prelude to The Lor...</td>\n","      <td>0.383562</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Harry Potter and the Sorcerer's Stone (Book 1)</td>\n","      <td>0.375160</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                           book_title  similarity\n","1   Harry Potter and the Prisoner of Azkaban (Book 3)    0.696095\n","2        Harry Potter and the Goblet of Fire (Book 4)    0.690532\n","3   The Perfect Storm : A True Story of Men Agains...    0.489702\n","4   Harry Potter and the Sorcerer's Stone (Harry P...    0.445134\n","5                                       Carolina Moon    0.403948\n","6   The Talented Mr. Ripley (Vintage Crime/Black L...    0.399915\n","7                                        Born in Fire    0.397422\n","8   Zen and the Art of Motorcycle Maintenance: An ...    0.394280\n","9   The Hobbit : The Enchanting Prelude to The Lor...    0.383562\n","10     Harry Potter and the Sorcerer's Stone (Book 1)    0.375160"]},"metadata":{},"output_type":"display_data"}],"source":["IBCF(encoding_df[encoding_df['label']==1], 'Harry Potter and the Chamber of Secrets (Book 2)' )"]},{"cell_type":"code","execution_count":83,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":381},"executionInfo":{"elapsed":510,"status":"ok","timestamp":1666567448608,"user":{"displayName":"강진영","userId":"15199531416785753238"},"user_tz":-540},"id":"5T8KUC76xFcU","outputId":"1cbed0ee-8ba5-4854-e2a5-5910957d8b42"},"outputs":[{"name":"stdout","output_type":"stream","text":["입력한 책 이름:  Harry Potter and the Chamber of Secrets (Book 2)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>book_title</th>\n","      <th>similarity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>Harry Potter and the Prisoner of Azkaban (Book 3)</td>\n","      <td>0.678289</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Harry Potter and the Sorcerer's Stone (Harry P...</td>\n","      <td>0.514990</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Harry Potter and the Sorcerer's Stone (Book 1)</td>\n","      <td>0.472443</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Harry Potter and the Goblet of Fire (Book 4)</td>\n","      <td>0.409339</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>The Hobbit: or There and Back Again</td>\n","      <td>0.319154</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>The Tao of Pooh</td>\n","      <td>0.310948</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>A Time to Kill</td>\n","      <td>0.310265</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>The Hitchhiker's Guide to the Galaxy</td>\n","      <td>0.309070</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>High Fidelity</td>\n","      <td>0.298845</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Four Past Midnight</td>\n","      <td>0.292082</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                           book_title  similarity\n","1   Harry Potter and the Prisoner of Azkaban (Book 3)    0.678289\n","2   Harry Potter and the Sorcerer's Stone (Harry P...    0.514990\n","3      Harry Potter and the Sorcerer's Stone (Book 1)    0.472443\n","4        Harry Potter and the Goblet of Fire (Book 4)    0.409339\n","5                 The Hobbit: or There and Back Again    0.319154\n","6                                     The Tao of Pooh    0.310948\n","7                                      A Time to Kill    0.310265\n","8                The Hitchhiker's Guide to the Galaxy    0.309070\n","9                                       High Fidelity    0.298845\n","10                                 Four Past Midnight    0.292082"]},"metadata":{},"output_type":"display_data"}],"source":["IBCF(encoding_df[encoding_df['label']==2], 'Harry Potter and the Chamber of Secrets (Book 2)' )"]},{"cell_type":"markdown","metadata":{"id":"0jUA8LhnhoSE"},"source":["### test set에 적용\n","\n","같은 방식을 train-test 분리한 데이터에 적용하여 성능을 비교해보겠습니다."]},{"cell_type":"code","execution_count":84,"metadata":{"id":"jhqesoDjWW3l"},"outputs":[],"source":["train_df = train_df.reset_index(drop=True)\n","test_df = test_df.reset_index(drop=True)\n","\n","df = pd.concat([train_df, test_df], axis=0) # train-test set을 concat하여 인코딩하고 다시 분할하도록 하겠습니다.\n","\n","df['category'] = df['category'].apply(lambda x: re.sub('[\\W_]+', ' ', x).strip()) #데이터 category의 대괄호를 풀어줍니다.\n","\n","encoding_df = pd.concat([df, pd.get_dummies(df[['category', 'language']])], axis=1) #카테고리와 언어로 one-hot-encoding을 수행합니다.\n","\n","train_df = encoding_df.iloc[:train_df.shape[0], :]\n","test_df = encoding_df.iloc[train_df.shape[0]:, :]"]},{"cell_type":"code","execution_count":85,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1316,"status":"ok","timestamp":1666567503637,"user":{"displayName":"강진영","userId":"15199531416785753238"},"user_tz":-540},"id":"3VU-L5Dt2lst","outputId":"1ffc511b-58a2-4e88-cce1-7c06f5992804"},"outputs":[{"data":{"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=3, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(n_clusters=3, random_state=42)</pre></div></div></div></div></div>"],"text/plain":["KMeans(n_clusters=3, random_state=42)"]},"execution_count":85,"metadata":{},"output_type":"execute_result"}],"source":["n=3 #군집개수를 정합니다.\n","km = KMeans(n_clusters=n, random_state=42)\n","km.fit(train_df.iloc[:,9:].copy()) #나이, 언어, 책 카테고리로 군집화를 수행하겠습니다.\n"]},{"cell_type":"code","execution_count":86,"metadata":{"id":"q_N2kE9was3Z"},"outputs":[],"source":["train_df = train_df.copy()\n","train_df['label'] = km.labels_"]},{"cell_type":"code","execution_count":87,"metadata":{"id":"gT6F55_zWOVF"},"outputs":[],"source":["test_df = test_df.copy()\n","test_df['label'] = km.predict(test_df.iloc[:,9:].copy())"]},{"cell_type":"code","execution_count":88,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":609,"status":"ok","timestamp":1666567521750,"user":{"displayName":"강진영","userId":"15199531416785753238"},"user_tz":-540},"id":"4R1tkvBrbsbR","outputId":"79944449-f177-47c3-b27d-aeea4fd7626a"},"outputs":[{"data":{"text/plain":["3.8189750985365176"]},"execution_count":88,"metadata":{},"output_type":"execute_result"}],"source":["rating = IBCF_predict_rating(train_df[train_df['label']==0], test_df[test_df['label']==0])\n","mean_squared_error(test_df[test_df['label']==0]['rating'], rating)**0.5"]},{"cell_type":"code","execution_count":89,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":747,"status":"ok","timestamp":1666567524173,"user":{"displayName":"강진영","userId":"15199531416785753238"},"user_tz":-540},"id":"M4xslLfmWOG1","outputId":"e4237b89-76ac-4ea3-ca0f-ba3de394e7a1"},"outputs":[{"data":{"text/plain":["3.9040023602646525"]},"execution_count":89,"metadata":{},"output_type":"execute_result"}],"source":["rating = IBCF_predict_rating(train_df[train_df['label']==1], test_df[test_df['label']==1])\n","mean_squared_error(test_df[test_df['label']==1]['rating'], rating)**0.5"]},{"cell_type":"code","execution_count":90,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":754,"status":"ok","timestamp":1666567526383,"user":{"displayName":"강진영","userId":"15199531416785753238"},"user_tz":-540},"id":"88ubsJu_cMZI","outputId":"ed729cf0-bfd3-4a25-995b-3b0cb3a4df9b"},"outputs":[{"data":{"text/plain":["3.856575105833"]},"execution_count":90,"metadata":{},"output_type":"execute_result"}],"source":["rating = IBCF_predict_rating(train_df[train_df['label']==2], test_df[test_df['label']==2])\n","mean_squared_error(test_df[test_df['label']==2]['rating'], rating)**0.5"]},{"cell_type":"markdown","metadata":{"id":"PryNavipGno1"},"source":["<font color='red'><b>**WARNING**</b></font> : **본 교육 콘텐츠의 지식재산권은 재단법인 네이버커넥트에 귀속됩니다. 본 콘텐츠를 어떠한 경로로든 외부로 유출 및 수정하는 행위를 엄격히 금합니다.** 다만, 비영리적 교육 및 연구활동에 한정되어 사용할 수 있으나 재단의 허락을 받아야 합니다. 이를 위반하는 경우, 관련 법률에 따라 책임을 질 수 있습니다."]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"camp","language":"python","name":"camp"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":0}
